{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "6b-rnn-english-numbers-GRU.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUzYi_kPIGS9",
        "colab_type": "text"
      },
      "source": [
        "# Predicting English word version of numbers using an RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWJf14ofIGS-",
        "colab_type": "text"
      },
      "source": [
        "We were using RNNs as part of our language model in the previous lesson.  Today, we will dive into more details of what RNNs are and how they work.  We will do this using the problem of trying to predict the English word version of numbers.\n",
        "\n",
        "Let's predict what should come next in this sequence:\n",
        "\n",
        "*eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve...*\n",
        "\n",
        "\n",
        "Jeremy created this synthetic dataset to have a better way to check if things are working, to debug, and to understand what was going on. When experimenting with new ideas, it can be nice to have a smaller dataset to do so, to quickly get a sense of whether your ideas are promising (for other examples, see [Imagenette and Imagewoof](https://github.com/fastai/imagenette)) This English word numbers will serve as a good dataset for learning about RNNs.  Our task today will be to predict which word comes next when counting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_rMgHyOIGTA",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqb-vP4TIGTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfGgLKuzIGTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs=64"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz_3ZYu3IGTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "24272f43-b72f-469b-b04a-ca0b1e2f489f"
      },
      "source": [
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "path.ls()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://files.fast.ai/data/examples/human_numbers.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/human_numbers/valid.txt'),\n",
              " PosixPath('/root/.fastai/data/human_numbers/train.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg8oTuUHIGTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readnums(d): return [', '.join(o.strip() for o in open(path/d).readlines())]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oTw1blIGTW",
        "colab_type": "text"
      },
      "source": [
        "train.txt gives us a sequence of numbers written out as English words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xriz5yZLIGTX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11f8ee6d-083d-4098-e008-4d21c4486b17"
      },
      "source": [
        "train_txt = readnums('train.txt'); train_txt[0][:80]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgxQAmh5IGTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ed62e43-3b70-4f20-c347-eb5b61e1f083"
      },
      "source": [
        "valid_txt = readnums('valid.txt'); valid_txt[0][-80:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "' nine thousand nine hundred ninety eight, nine thousand nine hundred ninety nine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIJ2a6N-IGTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "47cdf292-163b-4c8b-f389-df050323ec0f"
      },
      "source": [
        "train = TextList(train_txt, path=path)\n",
        "valid = TextList(valid_txt, path=path)\n",
        "\n",
        "src = ItemLists(path=path, train=train, valid=valid).label_for_lm()\n",
        "data = src.databunch(bs=bs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws86HOqPIGTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12f4a0c4-9163-40c6-c712-3e7a80e738ca"
      },
      "source": [
        "train[0].text[:80]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos one , two , three , four , five , six , seven , eight , nine , ten , eleve'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38T3WnNvIGTq",
        "colab_type": "text"
      },
      "source": [
        "`bptt` stands for *back-propagation through time*.  This tells us how many steps of history we are considering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc2TY0dHIGTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84a107ec-a26e-471e-b6f1-568998415e6c"
      },
      "source": [
        "data.bptt, len(data.valid_dl)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgMexjCzIGTx",
        "colab_type": "text"
      },
      "source": [
        "We have 3 batches in our validation set:\n",
        "\n",
        "13017 tokens, with about ~70 tokens in about a line of text, and 64 lines of text per batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6AoJAafIGTy",
        "colab_type": "text"
      },
      "source": [
        "We will store each batch in a separate variable, so we can walk through this to understand better what the RNN does at each step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1qn2eltIGTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it = iter(data.valid_dl)\n",
        "x1,y1 = next(it)\n",
        "x2,y2 = next(it)\n",
        "x3,y3 = next(it)\n",
        "it.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uaxg2u2-IGT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = data.valid_ds.vocab"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6pAeFdMIGT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = src.databunch(bs=bs, bptt=40)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK59jDayIGUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c0f8a31-9ee8-4a29-a5b2-316a21d9e803"
      },
      "source": [
        "x,y = data.one_batch()\n",
        "x.shape,y.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 40]), torch.Size([64, 40]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndJOek5SIGUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "441967aa-a9ab-4adc-88d0-dc6103486273"
      },
      "source": [
        "nv = len(v.itos); nv"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qQ4XN7aIGUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nh=56"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yn4jm0iIGUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss4(input,target): return F.cross_entropy(input, target[:,-1])\n",
        "def acc4 (input,target): return accuracy(input, target[:,-1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccAegwWZIGUS",
        "colab_type": "text"
      },
      "source": [
        "Layer names:\n",
        "- `i_h`: input to hidden\n",
        "- `h_h`: hidden to hidden\n",
        "- `h_o`: hidden to output\n",
        "- `bn`: batchnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "404-q8UOIGUT",
        "colab_type": "text"
      },
      "source": [
        "## Adding a GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWS68k79IGUU",
        "colab_type": "text"
      },
      "source": [
        "When you have long time scales and deeper networks, these become impossible to train.  One way to address this is to add mini-NN to decide how much of the green arrow and how much of the orange arrow to keep.  These mini-NNs can be GRUs or LSTMs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw3HcQvCIGUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.GRU(nh, nh, 1, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(1, bs, nh).cuda()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKnRBnX0IGUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab13817c-ad2b-4103-ad08-f94790be8bf2"
      },
      "source": [
        "nv, nh"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdU5FQnmIGUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model5(), metrics=accuracy)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy3rwHT0IGUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "a23d2114-f181-468f-8c54-2fea6afa8690"
      },
      "source": [
        "learn.fit_one_cycle(10, 1e-2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.205658</td>\n",
              "      <td>3.143939</td>\n",
              "      <td>0.418164</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.380147</td>\n",
              "      <td>2.213842</td>\n",
              "      <td>0.381836</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.916976</td>\n",
              "      <td>1.842677</td>\n",
              "      <td>0.455078</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.600322</td>\n",
              "      <td>1.543821</td>\n",
              "      <td>0.537240</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.289742</td>\n",
              "      <td>1.369751</td>\n",
              "      <td>0.625911</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.999305</td>\n",
              "      <td>1.245959</td>\n",
              "      <td>0.721615</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.756999</td>\n",
              "      <td>1.166967</td>\n",
              "      <td>0.773438</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.572688</td>\n",
              "      <td>1.105507</td>\n",
              "      <td>0.777214</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.438944</td>\n",
              "      <td>1.103407</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.346834</td>\n",
              "      <td>1.108730</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An8LGh-RIGUm",
        "colab_type": "text"
      },
      "source": [
        "## Let's make our own GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Eq4Wy0XIGUn",
        "colab_type": "text"
      },
      "source": [
        "### Using PyTorch's GRUCell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5OMFoayIGUo",
        "colab_type": "text"
      },
      "source": [
        "Axis 0 is the batch dimension, and axis 1 is the time dimension.  We want to loop through axis 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szEpNFlqIGUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_loop(cell, h, x):\n",
        "    res = []\n",
        "    for x_ in x.transpose(0,1):\n",
        "        h = cell(x_, h)\n",
        "        res.append(h)\n",
        "    return torch.stack(res, dim=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVdFGU6lIGUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model6(Model5):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnnc = nn.GRUCell(nh, nh)\n",
        "        self.h = torch.zeros(bs, nh).cuda()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res = rnn_loop(self.rnnc, self.h, self.i_h(x))\n",
        "        self.h = res[:,-1].detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZviXrapIGUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "619c17f0-231d-457a-bf36-131ce97d2aa7"
      },
      "source": [
        "learn = Learner(data, Model6(), metrics=accuracy)\n",
        "learn.fit_one_cycle(10, 1e-2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.394256</td>\n",
              "      <td>3.290702</td>\n",
              "      <td>0.292057</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.539216</td>\n",
              "      <td>2.465456</td>\n",
              "      <td>0.313281</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.993655</td>\n",
              "      <td>1.801866</td>\n",
              "      <td>0.481510</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.623773</td>\n",
              "      <td>1.690991</td>\n",
              "      <td>0.513737</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.307152</td>\n",
              "      <td>1.463491</td>\n",
              "      <td>0.605534</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.003013</td>\n",
              "      <td>1.198877</td>\n",
              "      <td>0.718294</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.743706</td>\n",
              "      <td>1.255735</td>\n",
              "      <td>0.719466</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.548399</td>\n",
              "      <td>1.387611</td>\n",
              "      <td>0.696940</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.411040</td>\n",
              "      <td>1.328145</td>\n",
              "      <td>0.710482</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.317735</td>\n",
              "      <td>1.354231</td>\n",
              "      <td>0.710742</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAILcDpnIGU2",
        "colab_type": "text"
      },
      "source": [
        "### With a custom GRUCell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58cUaaTbIGU3",
        "colab_type": "text"
      },
      "source": [
        "The following is based on code from [emadRad](https://github.com/emadRad/lstm-gru-pytorch/blob/master/lstm_gru.ipynb):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoLsKPu9IGU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.ni,self.nh = ni,nh\n",
        "        self.i2h = nn.Linear(ni, 3*nh)\n",
        "        self.h2h = nn.Linear(nh, 3*nh)\n",
        "    \n",
        "    def forward(self, x, h):\n",
        "        gate_x = self.i2h(x).squeeze()\n",
        "        gate_h = self.h2h(h).squeeze()\n",
        "        i_r,i_u,i_n = gate_x.chunk(3, 1)\n",
        "        h_r,h_u,h_n = gate_h.chunk(3, 1)\n",
        "        \n",
        "        resetgate = torch.sigmoid(i_r + h_r)\n",
        "        updategate = torch.sigmoid(i_u + h_u)\n",
        "        newgate = torch.tanh(i_n + (resetgate*h_n))\n",
        "        return updategate*h + (1-updategate)*newgate"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeYtAl6SIGU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model7(Model6):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnnc = GRUCell(nh,nh)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDOjTo2YIGU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "0d93e5aa-b2c6-4093-804e-75e38bcec33b"
      },
      "source": [
        "learn = Learner(data, Model7(), metrics=accuracy)\n",
        "learn.fit_one_cycle(10, 1e-2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.299754</td>\n",
              "      <td>3.177477</td>\n",
              "      <td>0.358594</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.455386</td>\n",
              "      <td>2.363856</td>\n",
              "      <td>0.316862</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.954433</td>\n",
              "      <td>1.827459</td>\n",
              "      <td>0.456510</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.623691</td>\n",
              "      <td>1.727087</td>\n",
              "      <td>0.510352</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.302369</td>\n",
              "      <td>1.673386</td>\n",
              "      <td>0.599414</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.002922</td>\n",
              "      <td>1.577916</td>\n",
              "      <td>0.647266</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.751934</td>\n",
              "      <td>1.558095</td>\n",
              "      <td>0.651953</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.562180</td>\n",
              "      <td>1.516425</td>\n",
              "      <td>0.676107</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.426494</td>\n",
              "      <td>1.567222</td>\n",
              "      <td>0.676497</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.333646</td>\n",
              "      <td>1.546266</td>\n",
              "      <td>0.679232</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J7siKLjIGVD",
        "colab_type": "text"
      },
      "source": [
        "### Connection to ULMFit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk1-AERWIGVD",
        "colab_type": "text"
      },
      "source": [
        "In the previous lesson, we were essentially swapping out `self.h_o` with a classifier in order to do classification on text.\n",
        "\n",
        "RNNs are just a refactored, fully-connected neural network.\n",
        "\n",
        "You can use the same approach for any sequence labeling task (part of speech, classifying whether material is sensitive,..)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHFLUZHwIGVE",
        "colab_type": "text"
      },
      "source": [
        "## fin"
      ]
    }
  ]
}